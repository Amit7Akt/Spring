<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>How we addressed an unforeseen use case in pthread_atfork()</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/14/how-we-addressed-unforeseen-use-case-pthreadatfork" /><author><name>Arjun Shankar</name></author><id>cf3d686d-7428-428d-8648-09b67590f46c</id><updated>2022-12-14T07:00:00Z</updated><published>2022-12-14T07:00:00Z</published><summary type="html">&lt;p&gt;While the &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/"&gt;POSIX&lt;/a&gt; standards specified by IEEE form the basis of compatibility between various operating systems and the portability of application code, sometimes unforeseen use cases can exercise an implementation in surprising ways and make us think about whether the interface itself could benefit from a more thorough specification.&lt;/p&gt; &lt;p&gt;As a member of Red Hat's Platform Tools team, I recently had the chance to witness and participate in the &lt;a href="https://www.gnu.org/software/libc/"&gt;glibc&lt;/a&gt; developer community's encounter with one such situation. As we worked on triaging and fixing what at first glance seemed to be a regression in the implementation of &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_atfork.html"&gt;pthread_atfork()&lt;/a&gt;, it soon became apparent that the interface might benefit from a more thorough treatment in its specification than it does already.&lt;/p&gt; &lt;h2&gt;pthread_atfork(): What it does and why it does it&lt;/h2&gt; &lt;p&gt;&lt;code&gt;pthread_atfork()&lt;/code&gt; is used by applications to set up &lt;em&gt;fork handlers&lt;/em&gt;—that is, functions that are called before and after processing a call to &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/fork.html"&gt;fork()&lt;/a&gt;. It is possible to register multiple sets of handlers, one for each call to &lt;code&gt;pthread_atfork()&lt;/code&gt;. Later, when &lt;code&gt;fork()&lt;/code&gt; is called, the runtime first executes the prepare handlers in the reverse order of registration, then processes the fork itself. After forking, the runtime executes the parent and child handlers in the corresponding processes, this time in the order of registration.&lt;/p&gt; &lt;p&gt;Here's how the standard defines &lt;code&gt;pthread_atfork()&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; int pthread_atfork (void (*prepare) (void), void (*parent) (void), void (*child) (void)); &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;According to the standard, the rationale behind providing this facility appears to be to tackle shortcomings in the semantics of &lt;code&gt;fork()&lt;/code&gt; itself. The standard offers the example of &lt;code&gt;fork()&lt;/code&gt; being called in one thread of a multi-threaded process while another thread is performing some operation and at the same time holding a lock that it expects to release once finished. &lt;code&gt;fork()&lt;/code&gt; only duplicates the calling thread in the child. Any other threads cease to exist in the child process. Therefore, after fork, the mutex remains locked, with no thread left to unlock it. &lt;code&gt;pthread_atfork()&lt;/code&gt; was intended as a solution to this kind of problem.&lt;/p&gt; &lt;p&gt;To quote the rationale from the POSIX standard:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;The &lt;code&gt;pthread_atfork()&lt;/code&gt; function was intended to provide multi-threaded libraries with a means to protect themselves from innocent application programs that call &lt;code&gt;fork()&lt;/code&gt;, and to provide multi-threaded application programs with a standard mechanism for protecting themselves from &lt;code&gt;fork()&lt;/code&gt; calls in a library routine or the application itself.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;The expected usage was that the prepare handler would acquire all mutex locks and the other two fork handlers would release them.&lt;/p&gt; &lt;h2&gt;A glibc bug report&lt;/h2&gt; &lt;p&gt;As I mentioned, sometimes interfaces are used in ways that weren't foreseen by the specification (or perhaps the implementation). In May 2019, Jeremy Drake reported a &lt;a href="https://sourceware.org/bugzilla/show_bug.cgi?id=24595"&gt;hang in glibc-2.28 during the execution of a pthread_atfork() handler&lt;/a&gt; when trying to use OpenVPN with a Gnuk smartcard. It was an excellent bug report, in which Jeremy debugged the issue all the way, eventually identifying its root cause.&lt;/p&gt; &lt;p&gt;One of the software components involved (&lt;code&gt;opensc&lt;/code&gt;) had registered a fork handler that &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/dlclose.html"&gt;dlclose()&lt;/a&gt;'d a dynamically loadable module (&lt;code&gt;pcsc-lite&lt;/code&gt;) in the child handler at fork time. Meanwhile, the module itself had registered its own set of fork handlers. Now, &lt;code&gt;dlclose()&lt;/code&gt;'ing a module means that any fork handlers registered by it should not be executed after the dlclose and should therefore implicitly be &lt;em&gt;deregistered&lt;/em&gt;. However, calling &lt;code&gt;dlclose()&lt;/code&gt; during the execution of a fork handler means that while &lt;em&gt;one&lt;/em&gt; handler is &lt;em&gt;running&lt;/em&gt;, another (that has either already been executed or is scheduled to be) needs to be removed from the list and the execution schedule. In other words, the list is modified while it's being walked and executed by the runtime. Depending on how the handler list is implemented/accessed, this can lead to a deadlock. The glibc implementation had been exhibiting the deadlock since release 2.28.&lt;/p&gt; &lt;p&gt;On the one hand, the standard already mentions that calling any non-&lt;a href="https://man7.org/linux/man-pages/man7/signal-safety.7.html"&gt;async-signal-safe&lt;/a&gt; function &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/fork.html"&gt;after fork&lt;/a&gt; and before an &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/exec.html"&gt;exec&lt;/a&gt; family function leads to undefined behavior. This is what happened in this particular case, so technically, it may be argued that this particular deadlock is not a bug. On the other hand, this had been working prior to release 2.28 and, as per the report, at least one application had made use of it.&lt;/p&gt; &lt;h2&gt;What had changed?&lt;/h2&gt; &lt;p&gt;Upstream glibc releases 2.27 and earlier were immune to this deadlock because of a linked-list based implementation of the fork handler list that used various synchronization primitives: a memory barrier and polling during handler execution, and locks during handler list modification where changes to the list were finalized via atomic operations. In glibc 2.28, a new array-based fork handler implementation was added that, in my opinion, was simpler, easier to reason about, and easier to maintain. In the new implementation, the handler list may only be modified or walked after obtaining a lock. This is what led to the deadlock: &lt;code&gt;fork()&lt;/code&gt; took a lock on the fork handler list during handler execution, and one of the handlers called &lt;code&gt;dlclose()&lt;/code&gt;, which tried to take the same lock in order to de-register a different fork handler that corresponded to the module being &lt;code&gt;dlclose()&lt;/code&gt;'d.&lt;/p&gt; &lt;h2&gt;An underspecified interface?&lt;/h2&gt; &lt;p&gt;While calling &lt;code&gt;dlclose()&lt;/code&gt; in a child handler qualifies as leading to undefined behavior, there are other cases that don't necessarily do so. For example, calling &lt;code&gt;dlclose()&lt;/code&gt; in a prepare or parent handler isn't forbidden by the standard. But it would lead to the same kind of deadlock. On top of that, it's also not explicitly forbidden to call &lt;code&gt;pthread_atfork()&lt;/code&gt; from a fork handler. However, doing so means registering a new handler during handler execution—and another deadlock. In fact, it appears that at &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1888660"&gt;least one of Red Hat's customers ran into this as well&lt;/a&gt;. FreeBSD libc, an entirely separate implementation, also runs into deadlocks under these circumstances. Glancing at the code, it appears that this is because FreeBSD libc quite reasonably also obtains a read-lock on the fork handler list during handler execution, and a write-lock during registration/deregistration. Given that two implementations run into the same issue, it appears that there is a case to be made that the standard should treat this class of use cases and clarify what the expected behavior should be when the execution of a handler causes registration or deregistration of another handler.&lt;/p&gt; &lt;h2&gt;The fix&lt;/h2&gt; &lt;p&gt;The Red Hat Bugzilla report eventually landed on my plate, and with some reading and a lot of advice from seniors on the glibc engineering team here, I began working on a patch. I chose to keep the dynamic array for its clean design, simply releasing the lock just before executing each handler. The idea is that we shouldn't hold implementation locks while executing an external callback. After a few iterations of testing and refining, I &lt;a href="https://sourceware.org/pipermail/libc-alpha/2022-April/138026.html"&gt;posted a patch upstream&lt;/a&gt; to the glibc development mailing list. Adhemerval Zanella, a prolific glibc developer, replied to my email almost immediately with a link to a patch he had been working on that I had overlooked. The test case Adhemerval had included in his patch exposed a hole in my own fix that I was then able to plug. I reworked my patch and included his test, and after another round of patch review from Adhemerval, the patch was &lt;a href="https://sourceware.org/git/?p=glibc.git;a=commit;h=52a103e237329b9f88a28513fe7506ffc3bd8ced"&gt;ready to commit&lt;/a&gt; in time for release 2.36. We backported the fix to 2.34 and 2.35 upstream as well as in &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; releases 8 and 9.&lt;/p&gt; &lt;h2&gt;What's next?&lt;/h2&gt; &lt;p&gt;Now that the deadlock is gone, there still remain a few open issues. First, there is a race condition where &lt;code&gt;dlclose()&lt;/code&gt; may race with handler execution during &lt;code&gt;fork()&lt;/code&gt;: just after the runtime chooses the next handler to be executed and releases the lock to begin executing the handler, the handler itself may ve deregistered and unmapped by a &lt;code&gt;dlclose()&lt;/code&gt;, leading to a segmentation fault. Next, when it comes to the specification itself, it sounds reasonable to file an issue with the &lt;a href="https://austingroupbugs.net"&gt;Austin Group&lt;/a&gt; asking for clarification regarding calling &lt;code&gt;dlclose()&lt;/code&gt; and &lt;code&gt;pthread_atfork()&lt;/code&gt; from a prepare or parent handler. Another open task is to better document the glibc implementation of &lt;code&gt;pthread_atfork()&lt;/code&gt; and bring it in line with the current implementation. I hope to get around to these as time and priority permit, or perhaps someone else will take them up. The upstream glibc developer community is a helpful and kind one, and we are always happy to welcome new contributors. In this case, the open docs issue is relatively beginner-friendly territory should someone want to get their feet wet.&lt;/p&gt; &lt;p&gt;(Thank you to Adhemerval Zanella, Florian Weimer, Carlos O'Donell, and Siddhesh Poyarekar for review and support.)&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/14/how-we-addressed-unforeseen-use-case-pthreadatfork" title="How we addressed an unforeseen use case in pthread_atfork()"&gt;How we addressed an unforeseen use case in pthread_atfork()&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Arjun Shankar</dc:creator><dc:date>2022-12-14T07:00:00Z</dc:date></entry><entry><title type="html">RESTEasy Releases</title><link rel="alternate" href="https://resteasy.github.io/2022/12/13/resteasy-releases/" /><author><name /></author><id>https://resteasy.github.io/2022/12/13/resteasy-releases/</id><updated>2022-12-13T18:11:11Z</updated><dc:creator /></entry><entry><title>Cryostat 2.2 improvements: Revamped archives views and more</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/13/cryostat-22-improvements-revamped-archives-views-and-more" /><author><name>Max Cao</name></author><id>1259d588-d356-48be-a70a-c8b01e86310b</id><updated>2022-12-13T07:00:00Z</updated><published>2022-12-13T07:00:00Z</published><summary type="html">&lt;p&gt;Cryostat is a container-native JVM application that provides a secure API for profiling and monitoring containers with &lt;a href="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u"&gt;JDK Flight Recorder&lt;/a&gt;. In the newest release, &lt;a href="https://developers.redhat.com/articles/2022/11/08/cryostat-22-released-enhanced-java-recording-features"&gt;Cryostat 2.2&lt;/a&gt;, three new and updated views for archived JDK flight recordings managed by Cryostat have been added to the web client, along with new recording filters and enhanced features for recording metadata and custom labels.&lt;/p&gt; &lt;h2&gt;All Targets archived recordings view&lt;/h2&gt; &lt;p&gt;Upon navigating to the Cryostat console tab titled &lt;strong&gt;Archives,&lt;/strong&gt; the first view we see is the &lt;strong&gt;All Targets&lt;/strong&gt; view (Figure 1). From this view, users can see all of their archived recordings from each target JVM as well as any re-uploaded archived recordings in one convenient location.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig1_25.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig1_25.png?itok=5LQYDdoz" width="600" height="300" alt="Screenshot of the All Targets archives view" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: All Targets archives view &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: All Targets archives view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;When we first come upon the view, we can see a card that includes three tabs, one titled &lt;strong&gt;All Targets,&lt;/strong&gt; the second titled &lt;strong&gt;All Archives,&lt;/strong&gt; and the last titled &lt;strong&gt;Uploads.&lt;/strong&gt; By default, the &lt;strong&gt;All Targets&lt;/strong&gt; view will be selected. A checkbox on this view includes the option to &lt;strong&gt;Hide targets with zero recordings.&lt;/strong&gt; By unchecking the box, we can see all targets Cryostat has discovered, with or without any associated archived recordings.&lt;/p&gt; &lt;p&gt;Let's try archiving a recording in one of the targets to see the view in action.&lt;/p&gt; &lt;p&gt;Navigate to the &lt;strong&gt;Recordings&lt;/strong&gt; tab on the Cryostat console and select any target JVM from the dropdown. If any &lt;a href="https://cryostat.io/guides/#store-jmx-credentials"&gt;JMX authorization issues&lt;/a&gt; or &lt;a href="https://cryostat.io/guides/#-add-a-trusted-certificate"&gt;SSL errors&lt;/a&gt; occur, learn to resolve these by reading the guides on the upstream &lt;a href="https://cryostat.io/guides/"&gt;Cryostat website&lt;/a&gt;. Click &lt;strong&gt;Create&lt;/strong&gt; to create a custom flight recording. For now, we can ignore any other new features and simply create a simple recording with these values:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Name:&lt;/strong&gt; Cryostat_Demo&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Archive on Stop:&lt;/strong&gt; Unchecked&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Duration:&lt;/strong&gt; 30 Seconds&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Template:&lt;/strong&gt; Profiling&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Create the recording by clicking the blue &lt;strong&gt;Create&lt;/strong&gt; button. Then archive the created recording by pressing the checkbox next to it and then pressing the &lt;strong&gt;Archive&lt;/strong&gt; button. Navigating to the &lt;strong&gt;Archived Recordings&lt;/strong&gt; tab of the target, we should see the newly archived recording.&lt;/p&gt; &lt;p&gt;Then, going back to the &lt;strong&gt;Archives&lt;/strong&gt; view on the &lt;strong&gt;Console&lt;/strong&gt; tab, we should see the target that we saved the recording from, as well as an updated archived recording count of &lt;code&gt;1&lt;/code&gt; (Figure 2).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig2_16.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig2_16.png?itok=Exu6Ukv3" width="600" height="300" alt="Screehshot showing how to view archived recording within nested table from target in the All Targets view" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Viewing archived recording within nested table from target in the All Targets view &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Viewing archived recording within nested table from target in the All Targets view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Clicking on the dropdown menu next to the target, we can see our newly archived recording along with labels and any actions Cryostat can perform on recordings, such as deleting or downloading it, viewing the associated report, or viewing the recording in Grafana.&lt;/p&gt; &lt;h2&gt;New All Archives archived recordings view&lt;/h2&gt; &lt;p&gt;Now, quickly navigate to the second tab of the &lt;strong&gt;Archives&lt;/strong&gt; section, titled &lt;strong&gt;All Archives.&lt;/strong&gt; After what you did in the previous section, you should now see a single row in a table under the &lt;strong&gt;Directory&lt;/strong&gt; header with a directory name (Figure 3).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig3_10.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig3_10.png?itok=fGKPgUWh" width="600" height="300" alt="Screenshot of the All Archives archives view" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: All Archives archives view &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: All Archives archives view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The &lt;strong&gt;All Archives&lt;/strong&gt; archived recordings view is a place to view any archived recordings that have been saved to Cryostat's storage. Any archived recording saved from a target JVM through Cryostat or re-uploaded to Cryostat will appear here, under its corresponding directory.&lt;/p&gt; &lt;p&gt;You can perform any actions on recordings within these directories as you could normally, such as &lt;a href="https://cryostat.io/guides/#view-a-recording-in-grafana"&gt;viewing a recording in Grafana&lt;/a&gt;, viewing an &lt;a href="https://cryostat.io/guides/#automated-analysis"&gt;automated analysis report&lt;/a&gt;, or editing labels (more on that later in the article).&lt;/p&gt; &lt;p&gt;If any target JVMs restart or exit when Cryostat is running, you may be unable to find previously saved archived recordings from that source target through the &lt;strong&gt;Recordings&lt;/strong&gt; tab. However, you will always be able to find them here in the &lt;strong&gt;All Archives&lt;/strong&gt; view under the directory table named with the same service URL as the specified target.&lt;/p&gt; &lt;p&gt;Note that if you are upgrading from version 2.1.0 of Cryostat to 2.2.0, any previously saved archived recordings may only appear here in the &lt;strong&gt;All Archives&lt;/strong&gt; view, under a directory named &lt;code&gt;lost&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Uploads view&lt;/h2&gt; &lt;p&gt;The final view that has been updated as part of Cryostat 2.2 is the &lt;strong&gt;Uploads&lt;/strong&gt; view. Users may now re-upload and access their JFR recordings through the &lt;strong&gt;Uploads&lt;/strong&gt; tab as part of the &lt;strong&gt;Archives&lt;/strong&gt; view.&lt;/p&gt; &lt;p&gt;Navigating to the &lt;strong&gt;Uploads&lt;/strong&gt; tab on the &lt;strong&gt;All Archives&lt;/strong&gt; view, we can see the &lt;strong&gt;Uploads&lt;/strong&gt; view where we are able to re-upload and interact with any re-uploaded archived JFR recording files by clicking the &lt;strong&gt;+&lt;/strong&gt; icon (Figure 4).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig4_8.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig4_8.png?itok=7GggrfK-" width="600" height="300" alt="Screenshot of the Uploads view" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Uploads view &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: Uploads view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;From here, we see many of the same actions as before on other views.&lt;/p&gt; &lt;p&gt;For more information on how to re-upload JFR recordings to Cryostat 2.2, see &lt;a href="https://access.redhat.com/documentation/en-us/openjdk/11/html/using_cryostat_to_manage_a_jfr_recording/assembly_archive-jfr-recordings_assembly_security-options#proc-uploading-recording-archive_assembly_archive-jfr-recordings"&gt;the official Red Hat guide&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Recording filters&lt;/h2&gt; &lt;p&gt;Another new feature in Cryostat 2.2 is the ability to selectively filter recordings in recording tables. To see this in action, navigate to the &lt;strong&gt;Recordings&lt;/strong&gt; tab, and select a target from the Target Select dropdown menu.&lt;/p&gt; &lt;p&gt;You can see that there is a new dropdown menu and search filter on the toolbar. Clicking the dropdown menu will bring a list of filter categories you can use to better selectively find your recording. You may apply multiple filters across multiple categories.&lt;/p&gt; &lt;p&gt;Let's try using the filtering system here in the Active Recordings table. As before, create a new recording with these configurations:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Name:&lt;/strong&gt; Cryostat_Demo_2&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Archive on Stop:&lt;/strong&gt; Unchecked&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Duration:&lt;/strong&gt; 30 Seconds&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Template:&lt;/strong&gt; Profiling&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;On the &lt;strong&gt;Active Recordings&lt;/strong&gt; tab, the first option in our filtering toolbar is the ability to filter selectively on the recording &lt;code&gt;Name&lt;/code&gt;. This is the default option.&lt;/p&gt; &lt;p&gt;Clicking the search bar will bring up a dropdown with the current list of names of recordings within the table. If there are many recordings within the table, you can also type within the bar to narrow down the search.&lt;/p&gt; &lt;p&gt;Click &lt;strong&gt;Cryostat_Demo&lt;/strong&gt; to filter selectively on the recording. Notice how an element shows up with the list of current filters currently selected (Figure 5). You can remove individual filters from the filter group (&lt;code&gt;Name&lt;/code&gt;, in this case), remove entire filter groups, and clear all filters.&lt;/p&gt; &lt;p&gt;Clicking any label of a recording under the &lt;strong&gt;Labels&lt;/strong&gt; column in the recordings table will also use the new filtering system to filter the view to only show recordings that are attached with that label.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig5_8.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig5_8.png?itok=vytNUYaw" width="600" height="292" alt="Screenshot showing the recording table with recording name filtering applied" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Recording table with recording name filtering applied. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Before moving on, let's remove all filters by using any of the filter clearing methods listed earlier.&lt;/p&gt; &lt;h2&gt;Enhanced labels&lt;/h2&gt; &lt;p&gt;The final Cryostat 2.2 feature we'll showcase in this article is the enhanced labels, which have been improved for better usability. The biggest change to labels is the ability to bulk edit a batch of labels that may be common to multiple recordings at once.&lt;/p&gt; &lt;p&gt;Let's see one final example. Stay within the &lt;strong&gt;Active Recordings&lt;/strong&gt; tab. Select both recordings created earlier and click the &lt;strong&gt;Edit Labels&lt;/strong&gt; button on the toolbar (Figure 6).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig6_5.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig6_5.png?itok=aunjWoqo" width="600" height="300" alt="Screenshot showing the editing recording labels menu" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Editing recording labels menu. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;A drawer will appear from the right where you can bulk edit common recording labels between all selected archived recordings. Let's remove a common label and add a new label to both recordings.&lt;/p&gt; &lt;p&gt;Press &lt;strong&gt;Edit&lt;/strong&gt; and remove the &lt;code&gt;template.name&lt;/code&gt; label by pressing the &lt;strong&gt;x&lt;/strong&gt; button next to the label. Then press the &lt;strong&gt;Add Label&lt;/strong&gt; button to create a new label key-value pair. Finally, save the changes.&lt;/p&gt; &lt;p&gt;You have now successfully Bulk-edited labels from several recordings at once.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This tutorial walks through the new &lt;strong&gt;Archives&lt;/strong&gt; view and explains the new features for enhanced recording metadata labels and recording filters. To learn how to operate on recordings using these labels, see this previous article on &lt;a href="https://developers.redhat.com/articles/2022/05/17/manage-jfr-across-instances-cryostat-and-graphql"&gt;Managing JFR across instances with Cryostat and GraphQL&lt;/a&gt;. For more information about Cryostat, visit &lt;a href="https://cryostat.io/get-started/"&gt;cryostat.io&lt;/a&gt;. For questions, comments and feedback, feel free to connect with us on &lt;a href="https://github.com/cryostatio"&gt;GitHub&lt;/a&gt; or join our &lt;a href="https://groups.google.com/g/cryostat-development"&gt;mailing list&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/13/cryostat-22-improvements-revamped-archives-views-and-more" title="Cryostat 2.2 improvements: Revamped archives views and more"&gt;Cryostat 2.2 improvements: Revamped archives views and more&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Max Cao</dc:creator><dc:date>2022-12-13T07:00:00Z</dc:date></entry><entry><title type="html">Keycloak 20.0.2 released</title><link rel="alternate" href="https://www.keycloak.org/2022/12/keycloak-2002-released" /><author><name /></author><id>https://www.keycloak.org/2022/12/keycloak-2002-released</id><updated>2022-12-13T00:00:00Z</updated><content type="html">To download the release go to . MIGRATION FROM 19.0 Before you upgrade remember to backup your database. If you are not on the previous release refer to for a complete list of migration changes. ALL RESOLVED ISSUES ENHANCEMENTS * Expiration for Admin Events keycloak BUGS * KC Operator Test WatchedSecretsTest.testSecretsAreWatched is unstable keycloak operator * Error in Core? ( Clients Client details Dedicated scopes): Cannot read properties of undefined (reading 'helpText') keycloak admin/ui * NPE in theme.getName() via getMainPage keycloak core * Failed to run scheduled task ClearExpiredAdminEvents Oracle keycloak storage * Flaky test: OpenshiftClientStorageTest.testCodeGrantFlowWithServiceAccountUsingOAuthRedirectReference keycloak testsuite * SAMLFilterServletAdapterTest fails on Oracle keycloak storage * Internal pipelines don't tests run for OracleDB or other database keycloak storage * clientID are base64 encoded in state uri param with non URI friendly base64 keycloak storage UPGRADING Before you upgrade remember to backup your database and check the for anything that may have changed.</content><dc:creator /></entry><entry><title>Kubernetes-native inner loop development with Quarkus</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/12/kubernetes-native-inner-loop-development-quarkus" /><author><name>Eric Deandrea</name></author><id>61ab4bf3-0be1-494b-8c0d-451db908fb92</id><updated>2022-12-12T07:00:00Z</updated><published>2022-12-12T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/microservices"&gt;Microservices&lt;/a&gt; today are often deployed on a platform such as &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;, which orchestrates the deployment and management of containerized applications. Microservices, however, don't exist in a vacuum. They typically communicate with other services, such as databases, message brokers, or other microservices. Therefore, an application usually consists of multiple services that form a complete solution.&lt;/p&gt; &lt;p&gt;But, as a developer, how do you develop and test an individual microservice that is part of a larger system? This article examines some common &lt;em&gt;inner-loop&lt;/em&gt; development cycle challenges and shows how Quarkus and other technologies help solve some of these challenges.&lt;/p&gt; &lt;h2&gt;What is the inner loop?&lt;/h2&gt; &lt;p&gt;Almost all software development is iterative. T&lt;span&gt;he &lt;em&gt;inner loop&lt;/em&gt; contains everything that happens on a developer's machine &lt;/span&gt;&lt;em&gt;before&lt;/em&gt;&lt;span&gt; committing code into version control. The inner loop is where a developer writes code, builds and tests it, and perhaps runs the code locally. In today's world, the inner loop could also include multiple commits to a &lt;/span&gt;&lt;a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests"&gt;Git pull request&lt;/a&gt;&lt;span&gt;, where a developer may commit multiple times against a specific feature until that feature is deemed complete.&lt;/span&gt;&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; The word &lt;em&gt;local&lt;/em&gt; is also up for debate in industry today as more and more remote development environments, such as &lt;a href="https://developers.redhat.com/developer-sandbox/ide"&gt;Red Hat OpenShift Dev Spaces&lt;/a&gt;, &lt;a href="https://gitpod.io"&gt;Gitpod&lt;/a&gt;, and &lt;a href="https://github.com/features/codespaces"&gt;GitHub Codespaces&lt;/a&gt; are available. This article does not differentiate between a developer machine and any of these kinds of environments. They are all viewed as &lt;em&gt;local&lt;/em&gt; in this article.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Inner loop&lt;/em&gt; shifts to &lt;em&gt;outer loop&lt;/em&gt; when code reaches a point in source control where it needs to be built, tested, scanned, and ultimately deployed by automated &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;continuous integration and deployment&lt;/a&gt; (CI/CD) processes. Figure 1 illustrates a simple inner loop and outer loop.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig1_24.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig1_24.png?itok=LsPqCLBm" width="600" height="320" alt="Diagram showing that the inner loop takes place on a developer's local machine, whereas the outer loop takes place within CI/CD processes." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The inner loop takes place on a developer's local machine, whereas the outer loop takes place within CI/CD processes. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Challenges of inner loop development&lt;/h2&gt; &lt;p&gt;Developing a single microservice in isolation is challenging enough without worrying about additional downstream services. How do you run a microservice in isolation on your local machine if it depends on other services for it to function properly?&lt;/p&gt; &lt;p&gt;Using various mocking techniques, you can to some extent get around the absence of required services when writing and running tests. Mocking techniques generally work great for testing. You can also use in-memory replacements for required services, such as an &lt;a href="https://www.h2database.com"&gt;H2 database&lt;/a&gt; instead of a separate database instance. Beyond that, if you want or need to run the application locally, you need a better solution.&lt;/p&gt; &lt;p&gt;Of course, you could &lt;em&gt;try&lt;/em&gt; to reproduce your application's entire environment on your development machine. But even if you could, would you really want to? Do you think a developer at Twitter or Netflix could reproduce their environment on their development machine? Figure 2 shows the complexity of their architectures. &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-1-a2f5d9a77813"&gt;Lyft also tried this approach&lt;/a&gt; and found it wasn't feasible or scalable.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig2.jpeg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig2.jpeg?itok=a2zAHnqd" width="600" height="264" alt="Diagram illustrating that major services such as Netflix and Twitter can easy have more than 500 microservices." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;span class="field field--name-field-source-url field--type-string field--label-hidden field__items"&gt; https://future.com/the-case-for-developer-experience &lt;/span&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Major services such as Netflix and Twitter can easy have more than 500 microservices. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Container-based inner loop solutions&lt;/h2&gt; &lt;p&gt;Using containers can help speed up and improve the inner loop development lifecycle. Containers can help isolate and provide a local instance of a dependent service. We'll look at a few popular tools and technologies for the inner loop.&lt;/p&gt; &lt;h3&gt;Docker Compose&lt;/h3&gt; &lt;p&gt;One common pattern is to use &lt;a href="https://docs.docker.com/compose"&gt;Docker Compose&lt;/a&gt; to run some of your microservice's dependent services (databases, message brokers, etc.) locally while you run, debug, and test your microservice. With Docker Compose, you define a set of containerized services that provide the capabilities required by your microservice. You can easily start, stop, and view logs from these containerized services.&lt;/p&gt; &lt;p&gt;However, there are a few downsides to using Docker Compose. First, you must maintain your Docker Compose configuration independently of your application's code. You must remember to make changes to the Docker Compose configuration as your application evolves, sometimes duplicating configuration between your application and your Docker Compose configuration.&lt;/p&gt; &lt;p&gt;Second, you are locked into using the Docker binary. For Windows and macOS users, &lt;a href="https://www.docker.com/pricing/faq"&gt;Docker Desktop is no longer free for many non-individual users&lt;/a&gt;. You are also prevented from using other container runtimes, such as &lt;a href="https://podman.io"&gt;Podman&lt;/a&gt;. &lt;a href="https://www.redhat.com/sysadmin/podman-docker-compose"&gt;Podman does support Docker Compose&lt;/a&gt;, but it doesn't support everything you can do with Docker Compose, especially on non-Linux machines.&lt;/p&gt; &lt;h3&gt;Testcontainers&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.testcontainers.org"&gt;Testcontainers&lt;/a&gt; is an excellent library for creating and managing container instances for various services when applications run tests. It provides lightweight, throwaway instances of common databases, message brokers, or anything else that can run in a container.&lt;/p&gt; &lt;p&gt;But Testcontainers is only a library. That means an application must incorporate it and &lt;em&gt;do&lt;/em&gt; something with it to realize its benefits. Generally speaking, applications that use Testcontainers do so when executing unit or integration tests, but not in production. A developer generally won't include the library in the application's dependencies because Testcontainers doesn't belong as a dependency when the application is deployed into a &lt;em&gt;real&lt;/em&gt; environment with &lt;em&gt;real&lt;/em&gt; services.&lt;/p&gt; &lt;h3&gt;Quarkus&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/quarkus"&gt;Quarkus&lt;/a&gt; is a Kubernetes-native Java application framework focusing on more than just feature sets. In addition to enabling fast startup times and low memory footprints compared to traditional Java applications, Quarkus ensures that every feature works well, with little to no configuration, in a highly intuitive way. The framework aims to make it trivial to develop simple things and easy to develop more complex ones. Beyond simply working well, Quarkus aims to bring &lt;a href="https://quarkus.io/developer-joy"&gt;Developer Joy&lt;/a&gt;, specifically targeting the inner loop development lifecycle.&lt;/p&gt; &lt;h4&gt;Dev mode&lt;/h4&gt; &lt;p&gt;The first part of the Quarkus Developer Joy story, live coding via &lt;a href="https://quarkus.io/guides/maven-tooling#dev-mode"&gt;Quarkus dev mode&lt;/a&gt;, improves and expedites the inner loop development process. When Quarkus dev mode starts, Quarkus automatically reflects code changes within the running application. Therefore, Quarkus combines the &lt;strong&gt;Write Code&lt;/strong&gt;, &lt;strong&gt;Build&lt;/strong&gt;, and &lt;strong&gt;Deploy/Run&lt;/strong&gt; steps of Figure 1's inner loop into a single step. Simply write code, interact with your application, and see your changes running with little to no delay.&lt;/p&gt; &lt;h4&gt;Dev Services&lt;/h4&gt; &lt;p&gt;A second part of the Quarkus Developer Joy story, &lt;a href="https://quarkus.io/guides/dev-services"&gt;Quarkus Dev Services&lt;/a&gt;, automatically provisions and configures supporting services, such as databases, message brokers, and more. When you run Quarkus in dev mode or execute tests, Quarkus examines all the extensions present. Quarkus then automatically starts any unconfigured and relevant service and configures the application to use that service.&lt;/p&gt; &lt;p&gt;Quarkus Dev Services uses Testcontainers, which we've already discussed, but in a manner completely transparent to the developer. The developer does not need to add the Testcontainers libraries, perform any integration or configuration, or write any code. Furthermore, Dev Services does not affect the application when it is deployed into a real environment with real services.&lt;/p&gt; &lt;p&gt;Additionally, if you have multiple Quarkus applications on your local machine and run them in dev mode, by default, Dev Services attempts to share the services between the applications. Sharing services is beneficial if you work on more than one application that uses the same service, such as a message broker.&lt;/p&gt; &lt;p&gt;Let's use the &lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;Quarkus Superheroes sample application&lt;/a&gt; as an example. The application consists of several microservices that together form an extensive system. Some microservices communicate synchronously via REST. Others are event-driven, producing and consuming events to and from &lt;a href="https://kafka.apache.org"&gt;Apache Kafka&lt;/a&gt;. Some microservices are reactive, whereas others are traditional. All the microservices produce metrics consumed by &lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt; and export tracing information to &lt;a href="https://opentelemetry.io"&gt;OpenTelemetry&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The source code for the application is on &lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;GitHub&lt;/a&gt; under an Apache 2.0 license. The system's architecture is shown in Figure 3.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig3_9.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig3_9.png?itok=wilWXzNN" width="600" height="686" alt="Architectural diagram of the Superheroes application, which has many microservices, some with dependencies." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: The Superheroes application has many microservices, some with dependencies. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: The Quarkus Superheroes application has many microservices and additional dependent services.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;In the Quarkus Superheroes sample application, you could start both the &lt;code&gt;rest-fights&lt;/code&gt; and &lt;code&gt;event-statistics&lt;/code&gt; services locally in dev mode. The &lt;code&gt;rest-fights&lt;/code&gt; dev mode starts a &lt;a href="https://www.mongodb.com"&gt;MongoDB&lt;/a&gt; container instance, an &lt;a href="https://www.apicur.io/registry"&gt;Apicurio Registry&lt;/a&gt; container instance, and an &lt;a href="https://kafka.apache.org"&gt;Apache Kafka&lt;/a&gt; container instance. The &lt;code&gt;event-statistics&lt;/code&gt; service also requires an Apicurio Registry instance and an Apache Kafka instance, so the instance started by the &lt;code&gt;rest-fights&lt;/code&gt; dev mode will be discovered and used by the &lt;code&gt;event-statistics&lt;/code&gt; service.&lt;/p&gt; &lt;h4&gt;Continuous testing&lt;/h4&gt; &lt;p&gt;A third part of the Quarkus Developer Joy story, &lt;a href="https://quarkus.io/guides/continuous-testing"&gt;continuous testing&lt;/a&gt;, provides instant feedback on code changes by immediately executing affected tests in the background. Quarkus detects which tests cover which code and reruns only the tests relevant to that code as you change it. Quarkus continuous testing combines testing with dev mode and Dev Services into a powerful inner loop productivity feature, shrinking all of Figure 1's inner loop lifecycle steps into a single step.&lt;/p&gt; &lt;h2&gt;Other inner loop solutions&lt;/h2&gt; &lt;p&gt;The solutions we've outlined thus far are extremely helpful with local inner loop development, especially if your microservice requires only a small set of other services, such as a database, or a database and message broker.&lt;/p&gt; &lt;p&gt;But when there are &lt;em&gt;lots&lt;/em&gt; of dependent services, trying to replicate them all on a local machine probably won't work well, if at all.&lt;/p&gt; &lt;p&gt;So what do you do? How do you get the speed and agility of inner loop development for an application when it depends on other services that you either &lt;em&gt;can't&lt;/em&gt; or &lt;em&gt;don't want to&lt;/em&gt; run locally?&lt;/p&gt; &lt;p&gt;One solution could be to manage an environment of &lt;em&gt;shared&lt;/em&gt; services. Each developer would then configure those services in their local setup, careful not to commit the configuration into source control.&lt;/p&gt; &lt;p&gt;Another solution could be to use Kubernetes, giving each developer a namespace where they can deploy what they need. The developer could then deploy the services and configure their local application to use them.&lt;/p&gt; &lt;p&gt;Both of these solutions &lt;em&gt;could&lt;/em&gt; work, but in reality, they usually end up with a problem: The microservice the developer is working on is &lt;em&gt;somewhere&lt;/em&gt; in the graph of services of an overall system. How does a developer trigger the microservice they care about to get called as part of a larger request or flow?&lt;/p&gt; &lt;p&gt;Wouldn't a better solution be to run the application locally, but make the larger system &lt;em&gt;think&lt;/em&gt; the application is actually deployed somewhere?&lt;/p&gt; &lt;p&gt;This kind of remote + local development model is becoming known as &lt;em&gt;remocal&lt;/em&gt;. It is an extremely powerful way to get immediate feedback during your inner loop development cycle while ensuring your application behaves properly in an environment that is close to or matches production.&lt;/p&gt; &lt;h3&gt;Quarkus remote development&lt;/h3&gt; &lt;p&gt;Another part of the Quarkus Developer Joy story, &lt;a href="https://quarkus.io/guides/maven-tooling#remote-development-mode"&gt;remote development&lt;/a&gt;, enables a developer to deploy an application into a remote environment and run Quarkus dev mode in that environment while doing live coding locally. Quarkus immediately synchronizes code changes to the remotely deployed instance.&lt;/p&gt; &lt;p&gt;Quarkus remote development allows a developer to develop the application in the same environment it will run in while having access to the same services it will have access to. Additionally, this capability greatly reduces the inner feedback loop while alleviating the "works on my machine" problem. Remote development also allows for quick and easy prototyping of new features and capabilities. Figure 4 illustrates how the remote development mode works.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/dev_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/dev_0.png?itok=68N800JI" width="600" height="353" alt="Quarkus remote dev mode incrementally synchronizes local code changes with a remote Quarkus application." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Quarkus remote dev mode incrementally synchronizes local code changes with a remote Quarkus application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;First, the application is deployed to Kubernetes, a virtual machine, a container, or just some Java virtual machine (JVM) somewhere. Once running, the developer runs the remote development mode on their local machine, connecting their local machine to the remote instance.&lt;/p&gt; &lt;p&gt;From there, development is just like live coding in Quarkus dev mode. As the developer makes code changes, Quarkus automatically compiles and pushes the changes to the remote instance.&lt;/p&gt; &lt;p&gt;Let's continue with the Quarkus Superheroes example from before. Let's assume the entire system is deployed into a Kubernetes cluster. Let's also assume you want to make changes to the &lt;code&gt;rest-fights&lt;/code&gt; microservice.&lt;/p&gt; &lt;p&gt;As shown in Figure 5, you start the &lt;code&gt;rest-fights&lt;/code&gt; microservice in remote dev mode on your local machine. The &lt;code&gt;rest-fights&lt;/code&gt; application running on the cluster connects to the MongoDB, Apicurio Registry, and Apache Kafka instances on the Kubernetes cluster.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig5_7.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig5_7.png?itok=fIwEDwZe" width="600" height="379" alt="Diagram showing changes to the local application during remote development send updates continuously to the services in the cloud." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Changes to the local application during remote development send updates continuously to the services in the cloud. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Changes to the local application in remote development mode continuously send updates to the remote instance.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You can then interact with the system through its user interface. Quarkus incrementally synchronizes the changes with the remote instance on the Kubernetes cluster as you make changes to the &lt;code&gt;rest-fights&lt;/code&gt; microservice. If you want, you could even use breakpoints within your IDE on your local machine to assist with debugging.&lt;/p&gt; &lt;h3&gt;Skupper&lt;/h3&gt; &lt;p&gt;&lt;a href="https://skupper.io"&gt;Skupper&lt;/a&gt; is a layer 7 service interconnect that enables secure communication across Kubernetes clusters without VPNs or special firewall rules. Using Skupper, an application can span multiple cloud providers, data centers, and regions. Figure 6 shows a high-level view of Skupper.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/overview.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/overview.png?itok=RXxczIfj" width="600" height="222" alt="Skupper connects services on different sites using routers at network layer 7." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Skupper connects services on different sites using routers at network layer 7. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Logically, Skupper connects services on different sites together to exist as a single site.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;With Skupper, you can create a distributed application comprised of microservices running in different namespaces within different Kubernetes clusters. Services exposed to Skupper are subsequently exposed to each namespace as if they existed in the namespace. Skupper creates proxy endpoints to make a service available within each of the namespaces where it is installed. Figure 7 shows a logical view of this architecture.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/view_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/view_0.png?itok=w67RqnD9" width="600" height="248" alt="Logically, Skupper can span multiple Kubernetes clusters and make remote services appear as local ones." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: Logically, Skupper can span multiple Kubernetes clusters and make remote services appear as local ones. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Why do we mention Skupper in an article about Kubernetes native inner loop development? Because in addition to bridging applications across Kubernetes clusters, a Skupper proxy can run on any machine, enabling bidirectional communication between the machine and the other Kubernetes clusters.&lt;/p&gt; &lt;p&gt;Logically, this is like a local machine inserted into the middle of a set of Kubernetes clusters. Services exposed to Skupper on the clusters can discover services exposed to the Skupper proxy on the local machine and vice versa.&lt;/p&gt; &lt;p&gt;Skupper can make our Quarkus Superheroes example even more interesting, taking it further from the remote development scenario we described earlier.&lt;/p&gt; &lt;p&gt;With Skupper, rather than continuously synchronizing changes to the &lt;code&gt;rest-fights&lt;/code&gt; service from a local instance to a remote instance, you could completely replace the remote &lt;code&gt;rest-fights&lt;/code&gt; instance with a local instance running Quarkus dev mode and continuous testing.&lt;/p&gt; &lt;p&gt;Skupper would then redirect traffic on the Kubernetes cluster &lt;em&gt;into&lt;/em&gt; the &lt;code&gt;rest-fights&lt;/code&gt; service running on your local machine. Any outgoing requests made by the &lt;code&gt;rest-fights&lt;/code&gt; service, such as connections to the MongoDB, Apicurio registry, and Apache Kafka instances, and even the &lt;code&gt;rest-heroes&lt;/code&gt; and &lt;code&gt;rest-villains&lt;/code&gt; services, would then be redirected back to the Kubernetes cluster. Figure 8 shows a logical view of what this architecture might look like.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig8_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig8_0.png?itok=W2SZheJC" width="512" height="592" alt="Diagram showing that, logically, Skupper can make it look like a local developer machine is inside a Kubernetes cluster." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: Logically, Skupper can make it look like a local developer machine is inside a Kubernetes cluster. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;You could even use Quarkus dev services to allow the &lt;code&gt;rest-fights&lt;/code&gt; microservice to provide its own local MongoDB instance rather than using the instance on the cluster, yet continue to let traffic to Kafka flow onto the cluster. This setup would enable other Kafka consumers listening on the same topic to continue functioning.&lt;/p&gt; &lt;p&gt;In this scenario, Quarkus continuously runs the tests of the &lt;code&gt;rest-fights&lt;/code&gt; microservice while a developer makes live code changes, all while traffic is continually flowing through the whole system on the Kubernetes cluster. The services could even be spread out to other Kubernetes clusters on different cloud providers in other regions of the world while traffic continues to flow through a developer's local machine.&lt;/p&gt; &lt;h2&gt;A better developer experience, whether local or distributed&lt;/h2&gt; &lt;p&gt;Parts &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-2-optimizing-for-fast-local-development-9f27a98b47ee"&gt;two&lt;/a&gt; and &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-3-extending-our-envoy-mesh-with-staging-fdaafafca82f"&gt;three&lt;/a&gt; of the previously mentioned &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-1-a2f5d9a77813"&gt;article series at Lyft&lt;/a&gt; show Lyft's approach to solving this problem, albeit using different technologies. As more and more services came to life, Lyft saw that what they were doing wasn't scaling and that they therefore needed a kind of "remocal" environment.&lt;/p&gt; &lt;p&gt;Quarkus was designed with many of these Developer Joy characteristics in mind. Quarkus helps developers iterate faster and contains built-in capabilities that alleviate many of these challenges and shorten the development lifecycles. Developers can focus on writing code.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/12/kubernetes-native-inner-loop-development-quarkus" title="Kubernetes-native inner loop development with Quarkus"&gt;Kubernetes-native inner loop development with Quarkus&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Eric Deandrea</dc:creator><dc:date>2022-12-12T07:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.31.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/12/kogito-1-31-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/12/kogito-1-31-0-released.html</id><updated>2022-12-12T01:49:18Z</updated><content type="html">We are glad to announce that the Kogito 1.31.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Quarkus 2.14 integration * First alpha version of the * New OpenAPI Callback example within Serverless Workflows * Sysout custom type now supports hardcoded strings (before it was only supporting expressions)  For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.25.0 artifacts are available at the . A detailed changelog for 1.31.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title type="html">Revised edition of WildFly books now available!</title><link rel="alternate" href="http://www.mastertheboss.com/articles/news/revised-edition-of-wildfly-books-now-available/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/articles/news/revised-edition-of-wildfly-books-now-available/</id><updated>2022-12-10T11:59:16Z</updated><content type="html">Fresh take on WildFly Administration Guide and Practical Enterprise Application development. Both books are now Jakarta EE 10 ready! WildFly 27 has just been released featuring lots of new features and Compatibility Certification for Jakarta EE 10. I’m thrilled to announce that the books “WildFly Administration Guide” and “Practical Enterprise Application development” are now on ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">New WildFly S2I and Runtime Multi-arch Images</title><link rel="alternate" href="https://wildfly.org//news/2022/12/10/wildfly-s2i-images-rename-multi-archs/" /><author><name>Jean-François Denise</name></author><id>https://wildfly.org//news/2022/12/10/wildfly-s2i-images-rename-multi-archs/</id><updated>2022-12-10T00:00:00Z</updated><content type="html">This article provides details on the new S2I and runtime multi-arch images. NEW WILDFLY S2I AND RUNTIME MULTI-ARCH IMAGES These new multi-arch images (linux/arm64 in addition to linux/amd64) have a different naming scheme than the current WildFly images to better handle multiple JDK versions and align with the tag scheme used for the WildFly centos7 docker images (as explained in blog post). Note The previous WildFly images are now deprecated and are no longer updated. The new multi-arch image names are: * Runtime image: quay.io/wildfly/wildfly-runtime:&lt;tag&gt; * S2I builder image: quay.io/wildfly/wildfly-s2i:&lt;tag&gt; This change is described in this . In short, the WildFly image names used to contain the JDK version (e.g: wildfly/wildfly-s2i-jdk11) leading to some lack of flexibility: * An increasing number of new images for each new JDK version. * No ability to identify a pair of images supporting the latest LTS (Long Term Support) JDK. The JDK version has been removed from the image name and moved to the image tag. In addition we have introduced a latest tag that identifies the images supporting the latest LTS JDK. You can identify the exact images version supporting a given JDK version: * quay.io/wildfly/wildfly-runtime:1.0.0-jdk11 used to be quay.io/wildfly/wildfly-runtime-jdk11:1.0.0 * quay.io/wildfly/wildfly-runtime:1.0.0-jdk17 used to be quay.io/wildfly/wildfly-runtime-jdk17:1.0.0 * quay.io/wildfly/wildfly-s2i:1.0.0-jdk11 used to be quay.io/wildfly/wildfly-s2i-jdk11:1.0.0 * quay.io/wildfly/wildfly-s2i:1.0.0-jdk17 used to be quay.io/wildfly/wildfly-s2i-jdk17:1.0.0 You can identify the latest images supporting a given JDK version: * quay.io/wildfly/wildfly-runtime:latest-jdk11 used to be quay.io/wildfly/wildfly-runtime-jdk11:latest * quay.io/wildfly/wildfly-runtime:latest-jdk17 used to be quay.io/wildfly/wildfly-runtime-jdk17:latest * quay.io/wildfly/wildfly-s2i:latest-jdk11 used to be quay.io/wildfly/wildfly-s2i-jdk11:latest * quay.io/wildfly/wildfly-s2i:latest-jdk17 used to be quay.io/wildfly/wildfly-s2i-jdk17:latest You can now identify the latest image supporting the latest LTS JDK version (JDK 17 at the time of this writing): * quay.io/wildfly/wildfly-runtime:latest * quay.io/wildfly/wildfly-s2i:latest Note Relying on this image tag implies that the JDK version will get automatically updated when a new LTS JDK is released and supported by the WildFly images. DEPRECATED SNAPSHOT MULTI-ARCH IMAGES Up to now, we were releasing multi-arch images as preview ones in the quay.io/wildfly-snapshots organization: * quay.io/wildfly-snapshots/wildfly-runtime-jdk11-multi-arch:latest * quay.io/wildfly-snapshots/wildfly-runtime-jdk17-multi-arch:latest * quay.io/wildfly-snapshots/wildfly-s2i-jdk11-multi-arch:latest * quay.io/wildfly-snapshots/wildfly-s2i-jdk17-multi-arch:latest These images are now deprecated and no longer updated. DEPRECATED WILDFLY IMAGES The following single-arch images are now deprecated and are no longer updated: * quay.io/wildfly/wildfly-runtime-jdk11:&lt;tag&gt; * quay.io/wildfly/wildfly-runtime-jdk17:&lt;tag&gt; * quay.io/wildfly/wildfly-s2i-jdk11:&lt;tag&gt; * quay.io/wildfly/wildfly-s2i-jdk17:&lt;tag&gt; NEW OPENSHIFT IMAGE STREAMS The previous image streams (, , , ) have been deprecated. The new image streams are: * WildFly s2i builder: * WildFly runtime: IMPACT ON HELM CHARTS FOR WILDFLY version 2.3.1 is required to use these new images. Helm Chart for WildFly now uses the quay.io/wildfly/wildfly-s2i:latest and quay.io/wildfly/wildfly-runtime:latest (latest LTS JDK) by default, used to be JDK11. If you have already installed the Helm Charts for WildFly, make sure to update your repository to the latest version. This is done by calling: helm repo update USING THE IMAGES The image naming change is transparent when using Helm Charts for WildFly. Usage of these images is covered by WildFly S2I , , wildfly-s2i image and wildfly-runtime image . SUMMARY With the introduction of these new multi-arch images, we are putting in place a long term tagging scheme to better support future JDK versions. You feedback as always is very welcome. Feel free to log these as new . Thank-you! JF Denise</content><dc:creator>Jean-François Denise</dc:creator></entry><entry><title>Top Ansible and automation resources of 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/09/best-2022-ansible-and-automation" /><author><name>Heiker Medina</name></author><id>2771afe8-efb6-427f-9d01-e358e4970bfe</id><updated>2022-12-09T17:48:43Z</updated><published>2022-12-09T17:48:43Z</published><summary type="html">&lt;p&gt;Developers are increasingly turning to &lt;a href="https://developers.redhat.com/topics/automation"&gt;automated development and deployment processes&lt;/a&gt; to meet the challenge of building cloud-native applications. In the era of cloud computing, your apps must react to &lt;a href="https://developers.redhat.com/topics/event-driven/"&gt;event-driven systems&lt;/a&gt; in scalable and flexible ways. Learn more about how Red Hat Developer readers used Ansible and Helm to make this possible in 2022.&lt;/p&gt; &lt;p&gt;Don't miss the other articles in our Best of 2022 series:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/12/01/top-linux-resources-2022"&gt;Top Linux resources of 2022&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/12/06/top-kubernetes-and-openshift-resources-2022"&gt;Top Kubernetes and OpenShift resources of 2022&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;API management&lt;/h2&gt; &lt;p&gt;Quarkus has made great progress in the past year, and its &lt;a href="https://developers.redhat.com/articles/2022/02/03/build-rest-api-ground-quarkus-20"&gt;tooling and overall usability have improved significantly&lt;/a&gt;. It is still fast and lightweight, and if you are looking for a modern Java framework for your next project, then Quarkus should be at the top of your list. If you're building an API, &lt;a href="https://developers.redhat.com/articles/2022/10/06/how-make-your-apis-more-discoverable"&gt;follow this guide by Vamsi Ravula and Hugo Guerrero&lt;/a&gt;. It's important to think about how people will find the API before you build it so that you don't have to come up with something on the fly.&lt;/p&gt; &lt;p&gt;To make sure your API is secure, use these &lt;a href="https://developers.redhat.com/articles/2022/10/20/10-essentials-mitigating-api-security-risks#how_red_hat_secures_apis"&gt;ten solutions and tools to help manage security&lt;/a&gt; throughout each step of the API life cycle.&lt;/p&gt; &lt;p&gt;To develop a successful API program, it is important to provide your developers with a developer portal that they can use to access your APIs. Vamsi Ravula shows you &lt;a href="https://developers.redhat.com/articles/2022/05/05/build-customized-developer-portal-manage-apis"&gt;how Red Hat 3scale API Management can be deployed on Red Hat OpenShift&lt;/a&gt; to provide a customizable developer portal. The procedure in this article shows the power of &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; as an application development platform, and how developers can get access to all of these components from the OpenShift console.&lt;/p&gt; &lt;h2&gt;Helm&lt;/h2&gt; &lt;p&gt;Jose Carvajal Hilario and Charles Moulliard demonstrated &lt;a href="https://developers.redhat.com/articles/2022/10/12/generate-helm-charts-using-dekorate"&gt;three ways that Dekorate simplifies Helm chart generation&lt;/a&gt;: it lets you easily generate Helm charts, it helps you map properties to be set when installing or updating your charts, and it allows you to use profiles.&lt;/p&gt; &lt;p&gt;Rohan Kumar shows you &lt;a href="https://developers.redhat.com/articles/2022/08/01/how-configure-helm-charts-using-jkube-part-2"&gt;how to set up Helm charts using Maven and Gradle plugins&lt;/a&gt;, with configuration options from Eclipse JKube. The article covers XML, Java properties, and resource fragments, finishing up by demonstrating how to configure a Helm registry to store your configuration.&lt;/p&gt; &lt;h2&gt;Ansible&lt;/h2&gt; &lt;p&gt;If you're interested in Ansible for middleware series, you'll want to read Romain Pelisse's article on &lt;a href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible"&gt;using Ansible to simplify the installation of Keycloak&lt;/a&gt;, an open source identity provider that enables single sign-on functionality for Web applications.&lt;/p&gt; &lt;p&gt;Red Hat Ansible Automation Platform also enables developers to &lt;a href="https://developers.redhat.com/articles/2022/09/07/5-examples-security-automation-ansible"&gt;automate the deployment and configuration of security tools&lt;/a&gt;, including firewalls, IDS/IPSes, SIEMs, PAMs, and EPPs. Jamie Beck and Himanshu Yadav explore five common use cases for automating these technologies.&lt;/p&gt; &lt;p&gt;In Harsha Cherukuri's article, he uses &lt;a href="https://developers.redhat.com/articles/2022/08/17/how-ansible-simplifies-jboss-eap-deployment-azure"&gt;Ansible to create Azure resources&lt;/a&gt;, deploys JBoss EAP using WildFly, and then deploys WildFly on an Azure VM.&lt;/p&gt; &lt;p&gt;Finally, revisit 2022's big Ansible announcement: &lt;a href="https://developers.redhat.com/blog/2022/11/29/whats-new-ansible-automation-platform-23"&gt;Ansible Automation Platform 2.3&lt;/a&gt; makes it easier than ever to automate system configuration, application deployment, and network settings across your entire enterprise via code.&lt;/p&gt; &lt;h2&gt;CI/CD&lt;/h2&gt; &lt;p&gt;In this &lt;a href="https://developers.redhat.com/articles/2022/01/13/developers-guide-cicd-and-gitops-jenkins-pipelines"&gt;tutorial article&lt;/a&gt;, Bob Reselman starts with a brief review of what Jenkins is and what it can do. Then, he explains how to use a Jenkinsfile to create deployments that combine CI/CD and GitOps.&lt;/p&gt; &lt;p&gt;Dotnet build-image is a tool that helps you containerize your .NET applications. You can use it to generate Dockerfiles and containerized images, and you'll discover with Tom Deseyn how to work with this tool in a GitHub workflow to &lt;a href="https://developers.redhat.com/articles/2022/08/01/containerize-net-applications-without-writing-dockerfiles"&gt;create an image from a .NET application and push it to a repository&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Red Hat Developer has put together a collection of our &lt;a href="https://developers.redhat.com/articles/2022/10/20/ultimate-cicd-resource-guide#recent_articles_to_explore_about_ci_cd"&gt;highest-performing articles on CI/CD&lt;/a&gt;. This article will introduce you to all things related to this topic.&lt;/p&gt; &lt;p&gt;In Christian Hernandez's article &lt;a href="https://developers.redhat.com/articles/2022/09/07/how-set-your-gitops-directory-structure"&gt;How to set up your GitOps directory structure&lt;/a&gt;, he discusses how to create repositories and directories in GitOps. Although there is no one answer, these basic best practices can help you see where to start.&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;Automation helps scale infrastructure, strengthen security, and improve customer experience. In the short e-book &lt;em&gt;An IT executive's guide to automation,&lt;/em&gt; you will discover the &lt;a href="https://developers.redhat.com/e-books/it-executives-guide-automation"&gt;benefits of a long-term transformative automation strategy&lt;/a&gt;. You'll also find out how to automate your infrastructure with Red Hat. Another resource to review is our &lt;a href="https://developers.redhat.com/cheat-sheets/git-cheat-sheet"&gt;basic Git commands cheat sheet&lt;/a&gt; The commands you'll learn more about help you work with files along with repositories and their branches, resolve merge conflicts, and more. You'll also learn how to move content between the remote repository and your local workspace, rebase or merge files between branches, and resolve merge conflicts when they occur.&lt;/p&gt; &lt;h2&gt;Learning paths&lt;/h2&gt; &lt;p&gt;You can simplify your IT tasks by creating a centralized and automated process with Ansible. Review &lt;a href="https://developers.redhat.com/learn/ansible"&gt;Red Hat Developer's Ansible learning path&lt;/a&gt; today!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/09/best-2022-ansible-and-automation" title="Top Ansible and automation resources of 2022"&gt;Top Ansible and automation resources of 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Heiker Medina</dc:creator><dc:date>2022-12-09T17:48:43Z</dc:date></entry><entry><title type="html">Using JBeret With Quarkus</title><link rel="alternate" href="https://jberet.github.io/jberet-quarkus/" /><author><name>阿男</name></author><id>https://jberet.github.io/jberet-quarkus/</id><updated>2022-12-09T00:00:00Z</updated><dc:creator>阿男</dc:creator></entry></feed>
